{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0762601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "groq_api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beabc715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002B10E3E97D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002B10E3F0390>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c910928f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Arjun! It's nice to meet you.\\n\\nThat's awesome that you're a Gen AI Developer! It's such an exciting field right now. \\n\\nWhat kind of projects are you working on?  I'm always eager to hear about what people are doing with generative AI. üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 22, 'total_tokens': 91, 'completion_time': 0.125454545, 'prompt_time': 0.002135825, 'queue_time': 0.24263195799999998, 'total_time': 0.12759037}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--3162f025-faf6-4a00-86b2-9ab300af7e3b-0', usage_metadata={'input_tokens': 22, 'output_tokens': 69, 'total_tokens': 91})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Arjun and Iam a Gen AI Developer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5152918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Arjun, and you are a Gen AI Developer!  \\n\\nIs there anything else you'd like to know or talk about? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 104, 'total_tokens': 137, 'completion_time': 0.06, 'prompt_time': 0.005529318, 'queue_time': 0.245730632, 'total_time': 0.065529318}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--5aea5b11-ed5d-4470-896b-3fe0a9e2b39b-0', usage_metadata={'input_tokens': 104, 'output_tokens': 33, 'total_tokens': 137})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, My name is Arjun and Iam a Gen AI Developer\"),\n",
    "    AIMessage(content=\"Hi Arjun,\\n\\nIt's nice to meet you! That's awesome that you're a Gen AI Developer. It's a really exciting field right now.\\n\\nWhat kind of projects are you working on?  I'm always interested to hear about what people are building with AI.\\n\"),\n",
    "    HumanMessage(content=\"Hey Whats my name and what do i do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84028cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store ={}\n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a3744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Arjun and Iam a Gen AI Developer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3706d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Arjun,\\n\\nIt's great to meet you! Being a Gen AI developer is fascinating. What kind of projects are you working on these days? I'm always eager to learn about the innovative things people are building with this technology.  \\n\\nPerhaps you could tell me about:\\n\\n* **The specific type of Gen AI you focus on:** (e.g., text generation, image creation, code generation)\\n* **A project you're particularly proud of:**\\n* **Any challenges you're facing in your work:**\\n\\nI'm here to listen and learn!  üòä  \\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f81c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Arjun, as you told me at the beginning of our conversation.  üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 234, 'total_tokens': 256, 'completion_time': 0.04, 'prompt_time': 0.00913723, 'queue_time': 0.243186939, 'total_time': 0.04913723}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--3a6d65c1-09b8-4b6c-8c8e-37e4799cab96-0', usage_metadata={'input_tokens': 234, 'output_tokens': 22, 'total_tokens': 256})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3e1cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it! üòä\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response =with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dc1157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant, Answer all the questions to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "265d060b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Arjun, it's nice to meet you! \\n\\nHow can I help you today? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 30, 'total_tokens': 56, 'completion_time': 0.047272727, 'prompt_time': 0.002158084, 'queue_time': 0.243241799, 'total_time': 0.049430811}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b3a93fcc-a083-4550-af66-84b23d982d7f-0', usage_metadata={'input_tokens': 30, 'output_tokens': 26, 'total_tokens': 56})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Arjun\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a81e67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb77741a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Arjun, it's nice to meet you!  \\n\\nI'm happy to help with any questions you have.  What can I do for you today? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 30, 'total_tokens': 69, 'completion_time': 0.070909091, 'prompt_time': 0.002296484, 'queue_time': 0.247670358, 'total_time': 0.073205575}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--deaa27ca-5443-4b37-a53f-de5e1b7b3333-0', usage_metadata={'input_tokens': 30, 'output_tokens': 39, 'total_tokens': 69})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response= with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Arjun\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6c6733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant. Answer all questions to the best of your ability in {language}\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "       \n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc0aefa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞ ‡≤Ö‡≤∞‡≥ç‡≤ú‡≥Å‡≤®‡≥ç! üòä \\n\\n‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø‡≤ï‡≤§‡≥ç‡≤µ‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≥Ä‡≤°‡≤≤‡≥Å ‡≤§‡≤Ø‡≤æ‡≤∞‡≤ø‡≤¶‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Å.  \\n‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤è‡≤®‡≥Å ‡≤¨‡≥á‡≤ï‡≥Å? \\n\\n(Hello Arjun! üòä I am ready to assist you. What can I do for you?) \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Arjun\")],\"language\":\"Kannada\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "681616e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1042f5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡≤®‡≤Æ‡≤∏‡≥ç‡≤§‡≥Ü ‡≤Ö‡≤∞‡≥ç‡≤ú‡≥Å‡≤®‡≥ç! üòä  \\n\\n‡≤®‡≤®‡≤ó‡≥Ü ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤≤‡≥Å ‡≤ñ‡≥Å‡≤∑‡≤ø üòä \\n ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤è‡≤®‡≥Å ‡≤§‡≤ø‡≤≥‡≤ø‡≤Ø‡≤¨‡≥á‡≤ï‡≥Å? \\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response= with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi im Arjun\")],\"language\":\"Kannada\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e081959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡≤®‡≥Ä‡≤µ‡≥Å ‡≤Ö‡≤∞‡≥ç‡≤ú‡≥Å‡≤®‡≥ç  ‡≤é‡≤Ç‡≤¶‡≥Å ‡≤π‡≥á‡≤≥‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø üòä  \\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Whats my name?\")],\"language\":\"Kannada\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d420f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data science\\SimplellmLCEL\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Arjun S\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter =model,\n",
    "    include_system = True,\n",
    "    allow_partial= False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12765692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you like vanilla ice cream!  üç¶'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"Kannada\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327fd7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
